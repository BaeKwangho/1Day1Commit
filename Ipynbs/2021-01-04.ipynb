{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# coursera NN and DL\n",
    "### Week 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,3,4])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.022235870361328\n",
      "1108.9260578155518\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "a = np.random.rand(1000000)\n",
    "b = np.random.rand(1000000)\n",
    "\n",
    "tic = time.time()\n",
    "c = np.dot(a,b)\n",
    "toc = time.time()\n",
    "print(str(1000*(toc-tic)))\n",
    "\n",
    "c = 0\n",
    "tic = time.time()\n",
    "for i in range(1000000):\n",
    "    c += a[i]*b[i]\n",
    "toc = time.time()\n",
    "print(str(1000*(toc-tic)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주피터 환경에서는 cpu가 주로 사용됨. gpu나 cpu 모두 병렬 연산이 수행되는데, (SIMD)\n",
    "이는 numpy나 python으로 하여금 한 지시로 병렬연산을 하여 훨씬 빠르게 처리할 수 있음을 나타냄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randn(3, 3)\n",
    "b = np.random.randn(3, 1)\n",
    "c = a*b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "formula is: $$sigmoid\\_derivative(x) = \\sigma'(x) = \\sigma(x) (1 - \\sigma(x))\\tag{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Week 2까지의 내용을 모두 해결하였음\n",
    "(assignment 1, 2를 제출, 클리어)\n",
    "<br>\n",
    "근데..\n",
    "<br>\n",
    "이게 과연 도움이 될지는 모름.\n",
    "<br>\n",
    "그래도 일단 오늘 이해한 것을 적어보는 시간을 가지겠음.\n",
    "\n",
    "### logistic regression 에서의 loss 및 cost로 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = open('/root/storage/DATA/pickle/checked','rb')\n",
    "data = pickle.load(x)\n",
    "x.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 200, 80, 97)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle = np.random.permutation(25)\n",
    "data_1 = cycle[:5]\n",
    "data_2 = cycle[5:10]\n",
    "\n",
    "true_data = np.ndarray((5,200,80,97))\n",
    "false_data = np.ndarray((5,200,80,97))\n",
    "for i in range(5):\n",
    "    true_data[i] = data[data_1[i]]\n",
    "    false_data[i] = data[data_2[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 7760) (1000, 7760) (1000, 1) (1000, 1)\n",
      "(1800, 7760) (200, 7760) (1800, 1) (200, 1)\n",
      "(7760, 1800) (7760, 200) (1, 1800) (1, 200)\n"
     ]
    }
   ],
   "source": [
    "true_X = true_data.reshape(true_data.shape[0]*true_data.shape[1],\n",
    "                          true_data.shape[2]*true_data.shape[3])\n",
    "false_X = false_data.reshape(false_data.shape[0]*false_data.shape[1],\n",
    "                          false_data.shape[2]*false_data.shape[3])\n",
    "true_Y = np.ones((true_X.shape[0],1))\n",
    "false_Y = np.zeros((false_X.shape[0],1))\n",
    "print(true_X.shape,false_X.shape,true_Y.shape,false_Y.shape)\n",
    "all_x = np.concatenate((true_X,false_X))\n",
    "all_y = np.concatenate((true_Y,false_Y))\n",
    "\n",
    "#all_x = np.random.shuffle(all_x[:])\n",
    "#all_y = np.random.shuffle(all_y[:])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x , test_x , train_y, test_y = train_test_split(all_x,all_y,test_size=0.1)\n",
    "print(train_x.shape,test_x.shape,train_y.shape,test_y.shape)\n",
    "train_x = train_x.reshape(train_x.shape[1],train_x.shape[0])\n",
    "test_x = test_x.reshape(test_x.shape[1],test_x.shape[0])\n",
    "train_y = train_y.reshape(train_y.shape[1],train_y.shape[0])\n",
    "test_y = test_y.reshape(test_y.shape[1],test_y.shape[0])\n",
    "print(train_x.shape,test_x.shape,train_y.shape,test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "iteration = 2000\n",
    "w = np.zeros((train_x.shape[0],1))\n",
    "b = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    x = 1/(1+np.exp(-x))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6931471805599446\n",
      "test accuracy : 53.5%\n",
      "train accuracy : 54.55555555555556%\n",
      "0.5768016817060015\n",
      "test accuracy : 53.5%\n",
      "train accuracy : 73.16666666666667%\n",
      "0.5248149221667037\n",
      "test accuracy : 51.5%\n",
      "train accuracy : 78.44444444444444%\n",
      "0.4863994721580847\n",
      "test accuracy : 51.5%\n",
      "train accuracy : 82.38888888888889%\n",
      "0.4556013483976805\n",
      "test accuracy : 51.5%\n",
      "train accuracy : 84.55555555555556%\n",
      "0.42984824000803146\n",
      "test accuracy : 51.5%\n",
      "train accuracy : 86.61111111111111%\n",
      "0.40772524109777186\n",
      "test accuracy : 53.0%\n",
      "train accuracy : 88.0%\n",
      "0.3883541687025399\n",
      "test accuracy : 54.5%\n",
      "train accuracy : 89.16666666666667%\n",
      "0.3711473118227767\n",
      "test accuracy : 53.5%\n",
      "train accuracy : 89.77777777777777%\n",
      "0.3556901681468778\n",
      "test accuracy : 52.0%\n",
      "train accuracy : 90.83333333333333%\n",
      "0.3416787043482114\n",
      "test accuracy : 51.5%\n",
      "train accuracy : 91.66666666666667%\n",
      "0.3288829412398794\n",
      "test accuracy : 50.5%\n",
      "train accuracy : 92.5%\n",
      "0.3171245039783114\n",
      "test accuracy : 51.0%\n",
      "train accuracy : 93.22222222222223%\n",
      "0.3062621201952068\n",
      "test accuracy : 51.0%\n",
      "train accuracy : 94.11111111111111%\n",
      "0.2961818953598832\n",
      "test accuracy : 52.5%\n",
      "train accuracy : 94.55555555555556%\n",
      "0.2867905877972648\n",
      "test accuracy : 53.0%\n",
      "train accuracy : 94.94444444444444%\n",
      "0.2780108358839657\n",
      "test accuracy : 53.0%\n",
      "train accuracy : 95.38888888888889%\n",
      "0.26977769437365123\n",
      "test accuracy : 53.0%\n",
      "train accuracy : 95.77777777777777%\n",
      "0.26203607133758533\n",
      "test accuracy : 53.0%\n",
      "train accuracy : 96.33333333333333%\n",
      "0.2547387985515831\n",
      "test accuracy : 53.0%\n",
      "train accuracy : 96.61111111111111%\n"
     ]
    }
   ],
   "source": [
    "m = train_x.shape[1]\n",
    "for i in range(iteration):\n",
    "    A = sigmoid(np.dot(w.T,train_x)+b)\n",
    "    cost = -np.sum(np.dot(train_y,np.log(A.T))+np.dot((1-train_y),np.log(1-A.T)))/m\n",
    "    \n",
    "    dw = np.dot(train_x,(A-train_y).T)/m\n",
    "    db = np.sum((A-train_y))/m\n",
    "    \n",
    "    cost = np.squeeze(cost)\n",
    "    \n",
    "    w = w - learning_rate * dw\n",
    "    b = b - learning_rate * db\n",
    "    \n",
    "    if i%100==0:\n",
    "        print(cost)\n",
    "        m2 = test_x.shape[1]\n",
    "        prediction = np.zeros((1,m2))\n",
    "        \n",
    "        w2 = w.reshape(test_x.shape[0],1)\n",
    "        A2 = sigmoid(np.dot(w2.T,test_x)+b)\n",
    "        for j in range(A2.shape[1]):\n",
    "            if A2[0,j]>=0.5:\n",
    "                prediction[0,j] = 1\n",
    "            else:\n",
    "                prediction[0,j] = 0\n",
    "        print('test accuracy : {}%'.format(100-np.mean(np.abs(prediction-test_y))*100))\n",
    "        m2 = train_x.shape[1]\n",
    "        prediction = np.zeros((1,m2))\n",
    "        \n",
    "        w2 = w.reshape(train_x.shape[0],1)\n",
    "        A2 = sigmoid(np.dot(w2.T,train_x)+b)\n",
    "        for j in range(A2.shape[1]):\n",
    "            if A2[0,j]>=0.5:\n",
    "                prediction[0,j] = 1\n",
    "            else:\n",
    "                prediction[0,j] = 0\n",
    "        print('train accuracy : {}%'.format(100-np.mean(np.abs(prediction-train_y))*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결과\n",
    "\n",
    "일단 뭐 원리에 대해서는 알 수 있었던 시간이었다.<br>\n",
    "logistic regression이었기 때문에 내가 주었던 옵션, 즉 5개의 클래스는 참, 5개의 클래스는 거짓이<br>\n",
    "test 단계에서 학습이 전혀 이루어 지지 않았음을 알 수 있다. 이는,<br>\n",
    "짐작하건데 클래스 개수를 두개씩으로 줄이면 가능하지 않을까 생각한다. 내일은 두개로 하는것을 간단히 해보고<br>\n",
    "다음 단계로 넘어갈 것이당"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
